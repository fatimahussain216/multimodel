# -*- coding: utf-8 -*-
"""multimodel.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C1p2Up3Dk8UWsovu3Q78Nh0N-jxneMQQ
"""
from langchain_text_splitters import CharacterTextSplitter
import streamlit as st
import pickle
from pdf2image import convert_from_path
import pytesseract
import numpy as np
import faiss
import requests

# text extract

def text_extract(pdf_path):
    """Text PDF extraction placeholder"""
    
    return "Extracted text from normal PDF"

def ocr_extract(pdf_path):
    """OCR PDF extraction"""
    pages = convert_from_path(pdf_path)
    full_text = ""
    for i, page in enumerate(pages):
        page_text = pytesseract.image_to_string(page, lang="eng+urd")
        full_text += f"\n\n--- Page {i+1} ---\n{page_text}"
    return full_text

# chunks
def chunk(text):
  splitter = CharacterTextSplitter(
    separator=" ",
    chunk_size=500,
    chunk_overlap=50
)
  chunks = splitter.split_text(text)
  return chunks

# embeddings

def embedding(text, model="text-embedding-3-small"):
    url = "https://api.openai.com/v1/embeddings"
    api_key=st.secrets["OPEN_API_KEY"]
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model, "input": text}
    response = requests.post(url, headers=headers, json=payload)
    if response.status_code != 200:
        raise Exception(f"API Error {response.status_code}: {response.text}")
    data = response.json()
    return np.array(data["data"][0]["embedding"], dtype=np.float32)

# faiss

def faiss_load(chunks, embeddings):
    dimension = embeddings[0].shape[0]
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings, dtype=np.float32))
    chunk_mapping = {i: chunks[i] for i in range(len(chunks))}
    return index, chunk_mapping



#def load_memory():
   # try:
    #    index = faiss.read_index("index.faiss")
     #   with open("chunks.pkl", "rb") as f:
      #      chunks = pickle.load(f)
       # print("FAISS memory loaded:", index.ntotal)
        #return index, chunks

    #except Exception as e:
     #   print("Memory load failed:", e)
      #  return None, {}
    
def retrive_k(query, index, chunk_mapping, k=3):
    #if not index or not chunk_mapping:
    #st.warning("Vector memory empty. Please index documents first.")
    #return []

    

    query_embedding = embedding(query)
    query_vector = np.array(query_embedding, dtype=np.float32).reshape(1, -1)

    distances, indices = index.search(query_vector, k)

    safe_chunks = []
    for i in indices[0]:
        try:
            if i != -1:
                safe_chunks.append(chunk_mapping[i])
        except:
            pass
    return safe_chunks
# prompt COMPLETION 

def build_prompt(context_chunks, query):
    if not context_chunks:
        context_chunks = ["No context available."]

    context = "\n".join(context_chunks)
    prompt = f"""
Use the following context to answer the question:

Context:
{context}

Question:
{query}
"""
    return prompt
    
#COMPLETION
def generate_completion(prompt, model="gpt-4.1-nano"):
    url = "https://api.euron.one/api/v1/euri/chat/completions"
    api_key=st.secrets["EURI_API_KEY"]
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model, "messages":[{"role":"user","content":prompt}],
               "max_tokens":110,"temperature":0.4}
    response = requests.post(url, headers=headers, json=payload)
    data = response.json()
    return data['choices'][0]['message']['content']

#STREAMLIT UI

st.header("OCR + Text RAG")


st.subheader("⚠️ Please upload PDF between 20 KB and 30 MB only")

pdf_file = st.file_uploader("Upload PDF", type=["pdf"])

mode = st.radio("Select mode", ["Text PDF", "OCR PDF"])
query = st.text_input("Enter your question")
if pdf_file and st.button("Process"):
    
    if mode == "Text PDF":
        text = text_extract(pdf_file)
    else:
        text = ocr_extract(pdf_file)
    
    
    chunks = chunk(text)
    
    
    embeddings = [embedding(c) for c in chunks]
    
    
    if len(embeddings) == 0:
        st.error("No embeddings found!")
    else:
        
        index, chunk_mapping = faiss_load(chunks, embeddings)
        
        
        
        
        
        context_chunks = retrive_k(query,index, chunk_mapping)
        
        
        prompt = build_prompt(context_chunks, query)
        
        
        ans = generate_completion(prompt)
        st.write(ans)
        st.success("PDF processed successfully")
