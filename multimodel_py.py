# -*- coding: utf-8 -*-
"""multimodel.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C1p2Up3Dk8UWsovu3Q78Nh0N-jxneMQQ
"""

import streamlit as st
import pickle
from pdf2image import convert_from_path
import pytesseract
import numpy as np
import faiss
import requests

# text extract

def text_extract(pdf_path):
    """Text PDF extraction placeholder"""
    # Agar PyMuPDF ya pdfplumber use karna ho to yahan implement
    return "Extracted text from normal PDF"

def ocr_extract(pdf_path):
    """OCR PDF extraction"""
    pages = convert_from_path(pdf_path)
    full_text = ""
    for i, page in enumerate(pages):
        page_text = pytesseract.image_to_string(page, lang="eng+urd")
        full_text += f"\n\n--- Page {i+1} ---\n{page_text}"
    return full_text

# chunks
def chunk(text):
  splitter = CharacterTextSplitter(
    separator=" ",
    chunk_size=500,
    chunk_overlap=50
)
  chunks = splitter.split_text(text)
  return chunks

# embeddings

def embedding(text, model="text-embedding-3-small"):
    url = "https://api.euron.one/api/v1/euri/embeddings"
    api_key="YOUR_REAL_KEY_HERE"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model, "input": text}
    response = requests.post(url, headers=headers, json=payload)
    if response.status_code != 200:
        raise Exception(f"API Error {response.status_code}: {response.text}")
    data = response.json()
    return np.array(data["data"][0]["embedding"], dtype=np.float32)

# faiss

def faiss_load(chunks, embeddings):
    dimension = embeddings[0].shape[0]
    index = faiss.IndexFlatL2(dimension)
    index.add(np.array(embeddings, dtype=np.float32))
    chunk_mapping = {i: chunks[i] for i in range(len(chunks))}
    return index, chunk_mapping

# memeory

def load_memory():
    try:
        index = faiss.read_index("index.faiss")
        with open("chunks.pkl", "rb") as f:
            chunks = pickle.load(f)
        return index, chunks
    except:
        return None, None

# reterival

def retrive_k(query, index, chunk_mapping, k=3):
    query_embedding = embedding(query)
    query_vector = np.array(query_embedding, dtype=np.float32).reshape(1, -1)
    distances, indices = index.search(query_vector, k)
    return [chunk_mapping[i] for i in indices[0]]

# prompt COMPLETION ----------

def build_prompt(context_chunks, query):
    context = "\n\n".join(context_chunks)
    return f"""use the following pieces of context to answer the question.
if you don't know the answer just say that you don't know, don't try to make up an answer.
context:{context}
question:{query}
answer:"""
#COMPLETION
def generate_completion(prompt, model="gpt-4.1-nano"):
    url = "https://api.euron.one/api/v1/euri/chat/completions"
    api_key="YOUR_REAL_KEY_HERE"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model, "messages":[{"role":"user","content":prompt}],
               "max_tokens":110,"temperature":0.4}
    response = requests.post(url, headers=headers, json=payload)
    data = response.json()
    return data['choices'][0]['message']['content']

#STREAMLIT UI

query = st.text_input("Enter your question")

mode = st.radio("Select mode", ["Text PDF", "OCR PDF"])

pdf_file = st.file_uploader("Upload PDF", type=["pdf"])

if pdf_file and st.button("Process"):

    if mode == "Text PDF":
        text = text_extract(pdf_file)
    else:
        text = ocr_extract(pdf_file)

    chunks = chunk(text)
    embeddings = [embedding(c) for c in chunks]
    index, chunk_mapping = faiss_load(chunks, embeddings)

    # memory load optional
    mem_index, mem_chunks = load_memory()

    context_chunks = retrive_k(query, index, chunk_mapping)
    prompt = build_prompt(context_chunks, query)
    ans = generate_completion(prompt)
    st.write(ans)
    st.success("PDF processed successfully")